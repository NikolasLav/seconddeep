# seconddeep
 Вторая попытка. 3 фотографии

А точнее вторая версия поисковика, но теперь уже с выдачей 3-х самых рейтинговых фотографии пользователя.

!!!ВАЖНО!!!
* Для старта работы бота начните печатать ему сообщение.
* Управление ботом через кнопки меню, и интерактивные сообщения в чате

 
Что хотелось бы отметить:
1. Принцип работы:
* Запрос данных о пользователе
* Затем, "под капотом":
	* Поиск на основании данных о пользователе
	* Подготовка выдачи (пачка из первых 10 анкет)
* по нажатию кнопки "поиск" - вывод результата в сообщениях
	* Подготовка следующей выдачи
* Можно менять возраст поиска, и город (ввод как ввиде текста, так и ID)

2. Реализован функционал (Дополнительные требования):
* В vk максимальная выдача при поиске 1000 человек. Подумать как это ограничение можно обойти.
	- Можно обойти только в случае поиска по каждому году, но для этого нужно, чтобы диапазон "ОТ" и "ДО"
	был не меньше 4-х лет. Опять
	НИКАК нельзя обойти, в т.ч. через offset.
	Целесообразно реализовать в асинхронном режиме, из-за длительности выполнения запросов, и довольно
	большого объёма реквеста (получаемого ответа от сервера).
* Добавить возможность ставить/убирать лайк, выбранной фотографии.
	- реализовано
* Добавлять человека в избранный список, используя БД
	- реализовано, через лайк к фотографии
* Добавлять человека в черный список чтобы он больше не попадался при поиске, используя БД
	- зачем, если есть условие в требованиях к сервису "Люди не должны повторяться при повторном поиске."
	Если только при очистке результатов сохранять ЧС? Организовать легко.
* К списку фотографий из аватарок добавлять список фотографий, где отмечен пользователь.
	- реализовано. Возвращает топ-3 (если есть, или меньше) фото, на кот. отмечен пользователь.
	- в виде фото отображаются только те, что доступны сообществу. чтобы отправить сообщение с аттачем от пользователя
	нужно следовать инструкции https://vk.com/dev/messages_api. Для учебных целей не целесообразно запрашивать "в 
	Поддержке тестовый доступ, подразумевающий работу методов секции Messages с ключами администраторов
	Вашего Standalone-приложения."

3. Прочее:
 1. Версия получилась многопользовательской, но однопоточной. Сейчас объясню...
 В классе Bot хранится словарь пользователей с идентификатором по их ID в VK. Хранится в течении жизни сессии.
 Легко обновляется и быстрее доступ, чем из БД SQL.
 2. Ботом может пользоваться любой пользователь, если ему не запрещены отправки сообщений от сообществ.
 Желательно состоять в сообществе (не проверял).
 Один пользователь "заводит" бота (с токеном пользователя и группы), остальные могут им при этом пользоваться.
 Можно реализовать пользовательские права, кстати (например для остановки бота), но я не стал заморачиваться в этой
 версии.
 3. В моей работе "чистые" SQL-запросы.
 Отказался от реализации SQLAlchemy в данном проекте, т.к. изучение вопроса о библиотеке дало представление о
 иногда неверном формировании запросов. Решил не привыкать к "плохому". Вопрос, конечно, спорный. (Практику по
 этой библиотеке SQLAlchemy я сдал, хоть она и не обязательная.)
 4. По совету одного из преподавателей постарался минимизировать используемое пространство в БД. Между сессиями
 достаточно сохранять лишь промежуточные результаты поиска, такие как:
	- анкеты, которые уже предлагались пользователю (можно очистить в настройках),
	- отметки в результатах: "добавлен избранное", "выдача показывалась", "забанен";
 остальное лучше обновлять в процессе работы приложения:
 	- данные пользователя - это быстро,
	- данные для поиска - будут как раз самые АКТУАЛЬНЫЕ.
 5. Не реализовал, хотя мог, множество функций, типа весов и сравнения интересов, т.к. во-первых, в однопоточном
 (синхронном) режиме выполнения это серьёзно повлияет на ожидание результата. И я, как раз взялся за новый подход -
 реализация приложения в асинхронном режиме. Надеюсь успеть сдать оба варианта.
 6. Во-вторых, неясно выполнение этих дополнительных требований по соблюдению нормы весов критериев поиска: нужно 
 сначала отрейтинговать ЛЮБОЙ ОДИН результат поиска, или нужно отрейтинговать по весам ВСЮ выборку полученную из
 users.search?
 Второй вариант весьма затратен по времени исполнения. Хотя, тут как раз и пригодился offset, если ограничить выдачу
 users.search штук по 20 анкет, допустим. Но такие пачки чем дальше к концу, тем будут хуже качеством - это раз.
 И тогда уже не сделать выборку по годам (писал об этом выше в проблеме с лимитом выдачи 1000 анкет)
 Довольно много непонятного, абстрактного, и приходится очень много додумывать в этом плане.
 Если бы был в ТЗ конкретный пример, или более подробное описание работы весов - это сэкономило бы массу времени.
 Тем неменее, я понимаю, что конкретное ТЗ в реальном мире - это редкий гость (?)... и всё равно...
 7. ...Это невероятный опыт работы! Спасибо за него! Мой первый серьёзный кейс :)